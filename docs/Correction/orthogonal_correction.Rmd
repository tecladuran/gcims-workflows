---
title: "Removing External Variability from GC-IMS Data: Linear Orthogonalization Approach"
author: "Tecla Duran Fort"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    fig_caption: yes
  html_document:
    toc: yes
    df_print: paged
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      fig.path = "orthogonal_correction_files/figure-latex/")
library(ggplot2)
library(dplyr)
library(tidyr)
library(tibble)
library(lubridate)
library(reshape2)
source("../../load_gcims_tools.R")
```

Load Peak Table

```{r load-data}
df <- read.csv("../../data/peak_table_var.csv")
```

## 1. Introduction

This document presents the implementation of a correction procedure based on External Parameter Orthogonalization (EPO) for GC-IMS Peak Table data. The aim is to remove systematic variability associated with external factors such as elapsed time and batch effects, which may obscure relevant chemical information.

The dataset under study originates from a single urine pool and is used to illustrate the orthogonalization approach, its mathematical foundations, R implementation, and the effect of sequential corrections applied in different orders.

As previously discussed in the [stability analysis report](https://github.com/tecladuran/gcims-workflows/blob/main/docs/stability_analysis.md), both elapsed time and batch number exhibit clear linear trends across the dataset and account for a substantial portion of the total variance. This motivates the use of orthogonalization techniques to isolate the relevant chemical signal from these external influences.

## 2. Theoretical Background

Orthogonal projection methods are commonly used in chemometrics and metabolomics to remove unwanted variability from experimental data. According to Roger et al. (2003), the signal space $\mathcal{S}$ can be decomposed into three orthogonal components:

$$
\mathcal{S} = \mathcal{C} \oplus \mathcal{G} \oplus \mathcal{R}
$$

where $\mathcal{C}$ contains meaningful chemical information, $\mathcal{G}$ represents systematic effects from external variables (e.g., time, batch), and $\mathcal{R}$ captures residual noise.

The aim is to estimate $\mathcal{G}$ and project the data onto its orthogonal complement, thereby removing the external component while preserving the informative signal. Roger et al. (2003) describe two main strategies to estimate this subspace:

-   by identifying the part of $X$ that is orthogonal to the response variable $Y$ (as in OSC or O-PLS),
-   or by directly modelling the subspace associated with the external parameter.

In the present project, we follow the second approach.

From a matrix $X \in \mathbb{R}^{n \times p}$, one can determine and use orthogonal projections (OPs) in the **sample space** or in the **signal space**:

-   An OP in the **sample space** is an $n \times n$ matrix, which acts on the **rows** of $X$ and consequently **left multiplies** $X$ .
-   An OP in the **signal space** is a $p \times p$ matrix, which acts on the **columns** of $X$ and consequently **right multiplies** $X$ .

Sample space OPs are used to separate sources of information related to the collection of the $n$ samples. Signal space OPs are used to separate signal features.

Corrections in the signal space are common for spectral data with fixed variable order and include methods like External Parameter Orthogonalisation.

However, in our case, the data consists of **peak tables**, where features are heterogeneous, non-ordered, and dataset-dependent. Applying projections in the signal space is thus not meaningful in this context.

Instead, we apply orthogonal projections in the **sample space**, removing components aligned with known external variables (e.g., elapsed time or batch).

Let $X \in \mathbb{R}^{n \times p}$ be the matrix of sample intensities (rows = samples, columns = peaks), and let $v \in \mathbb{R}^n$ be an external variable (e.g., elapsed time). We aim to remove from $X$ the component that is linearly aligned with $v$.

First, we **center** both $X$ and $v$ to eliminate constant offsets:

-   Let $\tilde{X} = X - \bar{X}$ (column-wise centering)
-   Let $\tilde{v} = v - \bar{v}$

Then, for each column $x_j$ of $\tilde{X}$, we compute its projection onto $\tilde{v}$ using:

$$
\text{proj}_{\tilde{v}}(x_j) = \frac{\tilde{v}^T x_j}{\tilde{v}^T \tilde{v}} \cdot \tilde{v}
$$

Stacking all projected components together:

$$
\tilde{X}_{\text{proj}} = \frac{\tilde{v} \tilde{v}^T}{\tilde{v}^T \tilde{v}} \cdot \tilde{X}
$$

This expression defines the **projection matrix** $P$:

$$
P = \frac{\tilde{v} \tilde{v}^T}{\tilde{v}^T \tilde{v}} \quad \Rightarrow \quad \tilde{X}_{\text{proj}} = P \tilde{X}
$$

The corrected data is obtained by subtracting the projection:

$$
\tilde{X}_{\text{corr}} = (I - P)\tilde{X}
$$

Finally, we add back the mean to preserve the original intensity scale:

$$
X_{\text{corr}} = \tilde{X}_{\text{corr}} + \bar{X}
$$

This sample space correction is mathematically simple, interpretable, and especially suited for **peak table** data.

It corresponds to a **linear orthogonalization** of the data against the external variable $v$, targeting the most dominant and evident source of drift in the dataset.

#### Methodological Considerations

Removing variation aligned with external variables risks discarding relevant signal if both are correlated. In this study, all samples come from the same pool, so time-related effects can safely be treated as artefacts. However, in datasets with true biological differences, **confounding** with acquisition order may lead to loss of meaningful information. Proper **randomization** is essential to avoid this.

## 3. Implementation

The following function implements a linear orthogonalization procedure that removes the component of the signal aligned with a known external variable (e.g., elapsed time or batch index). This is achieved by computing the projection of each variable onto the centered external variable and subtracting it from the data.

The function returns both the corrected data and the removed projection component.

```{r orth-function}
orthogonal_correction <- function(data, variable){
  data_mean <- colMeans(data)
  variable_mean <- mean(variable)
  data_centered <- sweep(data, 2, data_mean, "-")
  variable_centered <- variable - variable_mean
  scores <- as.numeric(t(data_centered) %*% variable_centered / sum(variable_centered^2))
  projection <- outer(variable_centered, scores)
  corrected_data <- data_centered - projection
  corrected_data <- sweep(corrected_data, 2, data_mean, "+")
  return(list(corrected = corrected_data, projection = projection))
}
```

## 4. Application to Peak Table

The orthogonalization function is applied sequentially to the GC-IMS peak intensity matrix. First, the effect of elapsed time is removed, followed by batch correction on the already time-corrected data. This stepwise approach ensures that each known source of external variability is accounted for.

The code below applies the corrections and stores the intermediate projections for further visualization and analysis.

```{r apply-correction}
intensities <- df %>% dplyr::select(starts_with("Cluster"))

# Correction for elapsed time
corr_time <- orthogonal_correction(intensities, df$elapsed_time)
intensities_time_corr <- corr_time$corrected

# Correction for batch
corr_batch <- orthogonal_correction(intensities_time_corr, df$batch)
intensities_final <- corr_batch$corrected

# Components for visualization
time_projection <- corr_time$projection
batch_projection <- corr_batch$projection
```

## 5. Method Visualization

In this section, we illustrate the step-by-step behavior of the orthogonalization procedure on a single example signal (one cluster). The goal is to understand how the correction operates on the raw data, isolating and removing the components associated with elapsed time and batch effects.

Each stage of the process is visualized separately: the original signal, the estimated component for each external variable, and the resulting corrected signals.

To assess the stability of the correction with respect to the order of application, we also visualize the results of applying the same procedure in reverse (first batch, then elapsed time).

```{r correction-visualization, fig.width=6, fig.height=2, echo=FALSE}

# Build visualization dataframe
example_cluster <- intensities[, 18]

# Calcular la mitjana del senyal original
signal_mean <- mean(example_cluster)

# Construir dataframe amb senyals centrades
df_vis <- data.frame(
  Sample = 1:length(example_cluster),
  Original = example_cluster - signal_mean,
  Time_Component = time_projection[, 18],
  After_Time_Correction = example_cluster - signal_mean - time_projection[, 18],
  Batch_Component = batch_projection[, 18],
  Fully_Corrected = intensities_final[, 18] - signal_mean
)

# Actualitzar el límit comú per a l'eix Y
y_limits <- range(df_vis)

# 1. Centered Original Signal
ggplot(df_vis, aes(x = Sample, y = Original)) +
  geom_line(color = "#253494", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "1. Original Signal", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 2. Elapsed Time Component
ggplot(df_vis, aes(x = Sample)) +
  geom_line(aes(y = Original), color = "#253494", size = 1, alpha = 0.5) +
  geom_line(aes(y = Time_Component), color = "#457b9d", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "2. Time Component",
       x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 3. After Time Correction
ggplot(df_vis, aes(x = Sample, y = After_Time_Correction)) +
  geom_line(color = "#1c9099", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "3. After Time Correction", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 4. Batch Component
ggplot(df_vis, aes(x = Sample)) +
  geom_line(aes(y = After_Time_Correction), color = "#1c9099", size = 1, alpha = 0.5) +
  geom_line(aes(y = Batch_Component), color = "#e9c46a", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "4. Batch Component",
       x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 5. Final Corrected Signal
ggplot(df_vis, aes(x = Sample, y = Fully_Corrected)) +
  geom_line(color = "#006d2c", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "5. Final Corrected Signal", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

```

After visualizing the sequential correction (elapsed time followed by batch), we now apply the same procedure in reverse order. This serves to confirm whether the correction is stable and order-independent for this dataset.

```{r inverse, fig.width=6, fig.height=2, echo=FALSE}

# Apply corrections in reverse order
corr_batch_first <- orthogonal_correction(intensities, df$batch)
intensities_batch_first <- corr_batch_first$corrected

corr_time_second <- orthogonal_correction(intensities_batch_first, df$elapsed_time)
intensities_inverse <- corr_time_second$corrected

# Intermediate projections
batch_projection_inv <- corr_batch_first$projection
time_projection_inv <- corr_time_second$projection

# Select same cluster and center
example_cluster_inv <- intensities[, 18]
signal_mean_inv <- mean(example_cluster_inv)

df_vis_inv <- data.frame(
  Sample = 1:length(example_cluster_inv),
  Original = example_cluster_inv - signal_mean_inv,
  Batch_Component = batch_projection_inv[, 18],
  After_Batch_Correction = example_cluster_inv - signal_mean_inv - batch_projection_inv[, 18],
  Time_Component = time_projection_inv[, 18],
  Fully_Corrected = intensities_inverse[, 18] - signal_mean_inv
)

y_limits_inv <- range(df_vis_inv)

# 1. Original Signal
ggplot(df_vis_inv, aes(x = Sample, y = Original)) +
  geom_line(color = "#1D3557", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "1. Original Signal", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 2. Batch Component
ggplot(df_vis_inv, aes(x = Sample)) +
  geom_line(aes(y = Original), color = "#1D3557", size = 1, alpha = 0.5) +
  geom_line(aes(y = Batch_Component), color = "#e9c46a", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "2. Batch Component", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 3. After Batch Correction
ggplot(df_vis_inv, aes(x = Sample, y = After_Batch_Correction)) +
  geom_line(color = "#2a9d8f", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "3. After Batch Correction", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 4. Time Component
ggplot(df_vis_inv, aes(x = Sample)) +
  geom_line(aes(y = After_Batch_Correction), color = "#2a9d8f", size = 1, alpha = 0.5) +
  geom_line(aes(y = Time_Component), color = "#457b9d", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "4. Time Component", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 5. Final Corrected Signal
ggplot(df_vis_inv, aes(x = Sample, y = Fully_Corrected)) +
  geom_line(color = "#264653", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "5. Final Corrected Signal", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())
```

The plots below demonstrate that the final corrected signal remains consistent, regardless of the order in which external effects are removed.

## 6. Results

### 6.1 Variance Explained

Variance explained before and after correction:

```{r explained-variance}
explained_variance <- function(data, variable){
  apply(data, 2, function(x){ summary(lm(x ~ variable))$r.squared }) %>% mean()
}

elapsed_original <- explained_variance(intensities, df$elapsed_time)
elapsed_corrected <- explained_variance(intensities_final, df$elapsed_time)
batch_original <- explained_variance(intensities, df$batch)
batch_corrected <- explained_variance(intensities_final, df$batch)

variance_df <- data.frame(
  Condition = c("Original", "Corrected"),
  Elapsed_Time = paste0(round(c(elapsed_original, elapsed_corrected) * 100, 2), " %"),
  Batch = paste0(round(c(batch_original, batch_corrected) * 100, 2), " %")
)


print(variance_df)
```

The reduction in explained variance after correction confirms the effective removal of systematic variability due to elapsed time and batch effects.

### 6.2 Principal Component Analysis (PCA) Visualizations

To better understand the structure of the data and the impact of the orthogonalization steps, we perform a Principal Component Analysis (PCA) on the cluster intensity matrix. The PCA is first computed on the original, uncorrected data, and the resulting components are used as a reference space for later projections.

We begin by displaying the projection of the original data on the first two principal components, colored by elapsed time.

```{r pca-original-dataframe, echo=FALSE}
# Scale original data before PCA
intensities_scaled <- scale(intensities)

# Perform PCA
pca <- prcomp(intensities_scaled)

# Extract explained variance for axis labels
explained_var <- summary(pca)$importance[2, ] * 100
axis_labels <- paste0("PC", 1:2, " (", round(explained_var[1:2], 1), "%)")

# Build PCA dataframe with metadata for coloring
pca_df <- data.frame(
  PC1 = pca$x[, 1],
  PC2 = pca$x[, 2],
  Elapsed_Time = df$elapsed_time,
  Batch = as.factor(df$batch)
)
```

```{r pca-originals, echo=FALSE, warning=FALSE, fig.width=12, fig.height=4.5, fig.cap = "PCA of original data colored by elapsed time (left) and by batch (right)", fig.align='center'}

p1 <- plot_pca(pca_df, "Elapsed_Time", "Colored by Elapsed Time",
               scale_color_gradientn(colours = hcl.colors(100, "YlGnBu")))

p2 <- plot_pca(pca_df, "Batch", "Colored by Batch",
               scale_color_discrete())

p1 + p2
```

```{r pca-variance-distribution, echo=FALSE, warning=FALSE, fig.width=5, fig.height=3, fig.cap = "Variance explained by each principal component (original data)", fig.align='center'}

var_df <- data.frame(PC = paste0("PC", 1:6),
                     Variance = explained_var[1:6])

ggplot(var_df, aes(x = PC, y = Variance)) +
  geom_col(fill = "#A8DADC") +
  theme_minimal(base_size = 13) +
  labs(title = "PCA Components — Variance Explained",
       x = "Principal Component", y = "Explained Variance (%)") +
  theme(axis.text.x = element_text(size = 11))
```

The following plots show how the data distribution changes after correcting for elapsed time. The PCA components are the same as in the original (uncorrected) analysis, and the corrected data is projected into this fixed PCA space for comparison.

```{r pca-correction-elapsed-fixed, echo=FALSE, warning=FALSE, fig.width=12, fig.height=4.5, fig.cap = "Projection before (left) and after (right) elapsed time correction, both colored by elapsed time", fig.align='center'}

# Project time-corrected data into the original PCA space
projected_time <- scale(intensities_time_corr,
                        center = attr(intensities_scaled, "scaled:center"),
                        scale = attr(intensities_scaled, "scaled:scale")) %*% pca$rotation

plot_pca_2(
  data1 = pca_df,
  data2 = data.frame(PC1 = projected_time[,1], PC2 = projected_time[,2], Elapsed_Time = df$elapsed_time),
  color_var = "Elapsed_Time",
  title1 = "Original",
  title2 = "After Time Correction",
  color_scale = scale_color_gradientn(colours = hcl.colors(100, "YlGnBu"))
)

```

The following plots show the impact of correcting for batch effects while leaving elapsed time uncorrected. As before, both datasets are projected into the same PCA space and colored by batch number.

```{r pca-correction-batch, echo=FALSE, warning=FALSE, fig.width=12, fig.height=4.5, fig.cap = "Projection before (left) and after (right) batch correction, both colored by batch", fig.align='center'}

# Project batch-corrected data into the original PCA space
projected_batch <- scale(intensities_batch_first,
                         center = attr(intensities_scaled, "scaled:center"),
                         scale = attr(intensities_scaled, "scaled:scale")) %*% pca$rotation

plot_pca_2(
  data1 = pca_df,
  data2 = data.frame(PC1 = projected_batch[,1], PC2 = projected_batch[,2], Batch = as.factor(df$batch)),
  color_var = "Batch",
  title1 = "Original",
  title2 = "After Batch Correction",
  color_scale = scale_color_discrete()
)
```

We now compare the full correction (elapsed time + batch) against the original data. Both datasets are projected into the same PCA space.

```{r pca-correction-full, echo=FALSE, warning=FALSE, fig.width=10, fig.height=4.5, fig.cap = "Projection before (left) and after (right) full correction (no coloring)", fig.align='center'}

# Project fully corrected data into the original PCA space
projected_full <- scale(intensities_final,
                        center = attr(intensities_scaled, "scaled:center"),
                        scale = attr(intensities_scaled, "scaled:scale")) %*% pca$rotation

# Datasets sense color
data1 <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2])
data2 <- data.frame(PC1 = projected_full[,1], PC2 = projected_full[,2])

p1 <- ggplot(data1, aes(x = PC1, y = PC2)) +
  geom_point(size = 2, color = "#888888") +
  coord_cartesian(xlim = range(c(data1$PC1, data2$PC1)),
                  ylim = range(c(data1$PC2, data2$PC2))) +
  theme_minimal(base_size = 13) +
  labs(title = "Original", x = axis_labels[1], y = axis_labels[2]) +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

p2 <- ggplot(data2, aes(x = PC1, y = PC2)) +
  geom_point(size = 2, color = "#1D3557") +
  coord_cartesian(xlim = range(c(data1$PC1, data2$PC1)),
                  ylim = range(c(data1$PC2, data2$PC2))) +
  theme_minimal(base_size = 13) +
  labs(title = "After Full Correction", x = axis_labels[1], y = axis_labels[2]) +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

p1 + p2
```

Finally, we perform a new PCA using the fully corrected dataset. The plots below show the distribution of samples in the new PCA space, colored by elapsed time and batch, respectively. A barplot of the explained variance is also included.

```{r pca-corrected-plot, echo=FALSE, warning=FALSE, fig.width=12, fig.height=4.5, fig.cap = "PCA of corrected data colored by elapsed time (left) and by batch (right)", fig.align='center'}

# PCA on corrected data
pca_corrected <- prcomp(scale(intensities_final))
explained_var_corr <- summary(pca_corrected)$importance[2, ] * 100
axis_labels <- paste0("PC", 1:2, " (", round(explained_var_corr[1:2], 1), "%)")

pca_df_corr <- data.frame(PC1 = pca_corrected$x[,1], PC2 = pca_corrected$x[,2],
                          Elapsed_Time = df$elapsed_time,
                          Batch = as.factor(df$batch))

p1 <- plot_pca(pca_df_corr, "Elapsed_Time", "Colored by Elapsed Time",
               scale_color_gradientn(colours = hcl.colors(100, "YlGnBu")))

p2 <- plot_pca(pca_df_corr, "Batch", "Colored by Batch",
               scale_color_discrete())

p1 + p2
```

```{r pca-variance-distribution-corr, echo=FALSE, warning=FALSE, fig.width=5, fig.height=3, fig.cap = "Variance explained by each principal component (corrected data)", fig.align='center'}

var_df_corr <- data.frame(PC = paste0("PC", 1:6),
                          Variance = explained_var_corr[1:6])

ggplot(var_df_corr, aes(x = PC, y = Variance)) +
  geom_col(fill = "#A8DADC") +
  theme_minimal(base_size = 13) +
  labs(title = "Corrected PCA — Variance Explained",
       x = "Principal Component", y = "Explained Variance (%)") +
  theme(axis.text.x = element_text(size = 11))

```
