---
title: "Removing External Variability from GC-IMS Data: A Linear Orthogonalization Approach"
author: "Tecla Duran Fort"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    fig_caption: true
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      fig.path = "linear_correction_files/figure-latex/")
library(ggplot2)
library(dplyr)
library(tidyr)
library(tibble)
library(lubridate)
library(reshape2)
source("../../load_gcims_tools.R")
```

Load Peak Table

```{r load-data}
df <- read.csv("../../data/peak_table_var.csv")
```

## 1. Introduction

This document presents the implementation of a correction procedure based on External Parameter Orthogonalization (EPO) for GC-IMS Peak Table data. The aim is to remove systematic variability associated with external factors such as elapsed time and batch effects, which may obscure relevant chemical information.

The dataset under study originates from a single urine pool and is used to illustrate the orthogonalization approach, its mathematical foundations, R implementation, and the effect of sequential corrections applied in different orders.

As previously discussed in the [stability analysis report](https://github.com/tecladuran/gcims-workflows/blob/main/docs/stability_analysis.md), both elapsed time and batch number exhibit clear linear trends across the dataset and account for a substantial portion of the total variance. This motivates the use of orthogonalization techniques to isolate the relevant chemical signal from these external influences.

## 2. Theoretical Background

In line with the theoretical framework proposed by Roger et al. (2003), the signal space $\mathcal{S}$ can be decomposed as:

$$
\mathcal{S} = \mathcal{C} \oplus \mathcal{G} \oplus \mathcal{R}
$$

where:\
- $\mathcal{C}$ corresponds to the informative signal related to meaningful chemical variation,\
- $\mathcal{G}$ contains systematic perturbations associated with external parameters (e.g., temperature, batch, time),\
- $\mathcal{R}$ captures noise and other residual effects, including potential covariances.

Methods such as **External Parameter Orthogonalization (EPO)** aim to isolate and remove $\mathcal{G}$ by projecting the data matrix $X$ onto the orthogonal complement of the subspace spanned by external influences. Mathematically, if an estimate $\hat{Q}$ of the projection matrix onto $\mathcal{G}$ is available, the corrected data can be computed as:

$$
X^* = X(I - \hat{Q})
$$

In typical EPO implementations, $\hat{Q}$ is derived from a **Principal Component Analysis (PCA)** on difference spectra across levels of the external variable, often requiring replicate measurements under controlled variation.

### 2.1. Application to the urine pool dataset

In our case, all samples originate from a single **urine pool**, which means that their initial chemical composition is expected to be identical (the informative subspace $\mathcal{C}$ is therefore theoretically of dimension 1).\
However, we observe progressive changes in the signal over time and across batches. These differences may originate from various sources --- including biochemical reactions, temperature fluctuations, or instrumental drift --- and the exact contribution of each factor remains uncertain.

This means that not all observed variability can be immediately dismissed as noise or artefact. Some of it may reflect real chemical transformations.\
While some of these changes might, in principle, belong to the informative space $\mathcal{C}$, they are not associated with any intended experimental grouping. Since they appear to follow the acquisition order or elapsed time, we treat them as artefactual in this context. They are therefore included in $\mathcal{G}$, as they represent uncontrolled variability that could obscure meaningful biological differences.

As detailed in the [linearity analysis report] (https://github.com/tecladuran/gcims-workflows/blob/main/docs/linearity_report.md), we observed clear linear trends in signal intensity with respect to elapsed time and batch index. These trends suggest that the dominant source of unwanted variability is linearly correlated with known external variables. Consequently, rather than estimating $\mathcal{G}$ via PCA as in standard EPO, we adopt a simplified approach: we define the external variable $v \in \mathbb{R}^n$ (e.g., elapsed time), and directly remove the component of $X$ aligned with $v$.

The corrected matrix is obtained as:

$$
X_{\text{corr}} = (X - \bar{X}) - (v - \bar{v}) \frac{(X - \bar{X})^T (v - \bar{v})}{(v - \bar{v})^T (v - \bar{v})} + \bar{X}
$$

which is equivalent to:

$$
\hat{Q} = \frac{(v - \bar{v})(v - \bar{v})^T}{(v - \bar{v})^T (v - \bar{v})} \quad \Rightarrow \quad X_{\text{corr}} = X(I - \hat{Q})
$$

This formulation corresponds to a **linear orthogonalization** of the signal against the direction defined by $v$, and allows us to eliminate the influence of known external variables without estimating a full latent space.

We are aware that other sources of variability --- potentially nonlinear or multidimensional --- may also be present. However, in this case, we explicitly target the linear component of the drift, as it is the most evident and dominant in our dataset.

#### Methodological Considerations

It is important to note that **removing components aligned with external variables** comes with the risk of also removing part of the signal of interest if both lie in similar directions. While in this study we intentionally remove time-related effects assuming all samples come from the same pool, this consideration becomes critical when analyzing **datasets with real biological differences between samples**.

In such cases, if the group separation of interest is **confounded** with external trends (e.g., if all samples from one group were measured earlier in the sequence), orthogonalization might **inadvertently remove the relevant signal**. This underlines the importance of proper **sample randomization** during acquisition to ensure that true group differences are not aligned with experimental artifacts.

We will return to this point in future sections, where the preservation of meaningful variation across groups will be essential for correct classification and interpretation.

## 3. Implementation

The following function implements a linear orthogonalization procedure that removes the component of the signal aligned with a known external variable (e.g., elapsed time or batch index). This is achieved by computing the projection of each variable onto the centered external variable and subtracting it from the data.

The function returns both the corrected data and the removed projection component.

```{r orth-function}
correction <- function(data, variable){
  data_mean <- colMeans(data)
  variable_mean <- mean(variable)
  data_centered <- sweep(data, 2, data_mean, "-")
  variable_centered <- variable - variable_mean
  scores <- as.numeric(t(data_centered) %*% variable_centered / sum(variable_centered^2))
  projection <- outer(variable_centered, scores)
  corrected_data <- data_centered - projection
  corrected_data <- sweep(corrected_data, 2, data_mean, "+")
  return(list(corrected = corrected_data, projection = projection))
}
```



## 4. Application to Peak Table

The orthogonalization function is applied sequentially to the GC-IMS peak intensity matrix. First, the effect of elapsed time is removed, followed by batch correction on the already time-corrected data. This stepwise approach ensures that each known source of external variability is accounted for.

The code below applies the corrections and stores the intermediate projections for further visualization and analysis.

```{r apply-correction}
intensities <- df %>% dplyr::select(starts_with("Cluster"))

# Correction for elapsed time
corr_time <- correction(intensities, df$elapsed_time)
intensities_time_corr <- corr_time$corrected

# Correction for batch
corr_batch <- correction(intensities_time_corr, df$batch)
intensities_final <- corr_batch$corrected

# Components for visualization
time_projection <- corr_time$projection
batch_projection <- corr_batch$projection
```

## 5. Method Visualization

In this section, we illustrate the step-by-step behavior of the orthogonalization procedure on a single example signal (one cluster). The goal is to understand how the correction operates on the raw data, isolating and removing the components associated with elapsed time and batch effects.

Each stage of the process is visualized separately: the original signal, the estimated component for each external variable, and the resulting corrected signals.

To assess the stability of the correction with respect to the order of application, we also visualize the results of applying the same procedure in reverse (first batch, then elapsed time).

```{r correction-visualization, fig.width=6, fig.height=2, echo=FALSE}

# Build visualization dataframe
example_cluster <- intensities[, 18]

# Calcular la mitjana del senyal original
signal_mean <- mean(example_cluster)

# Construir dataframe amb senyals centrades
df_vis <- data.frame(
  Sample = 1:length(example_cluster),
  Original = example_cluster - signal_mean,
  Time_Component = time_projection[, 18],
  After_Time_Correction = example_cluster - signal_mean - time_projection[, 18],
  Batch_Component = batch_projection[, 18],
  Fully_Corrected = intensities_final[, 18] - signal_mean
)

# Actualitzar el límit comú per a l'eix Y
y_limits <- range(df_vis)

# 1. Centered Original Signal
ggplot(df_vis, aes(x = Sample, y = Original)) +
  geom_line(color = "#253494", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "1. Original Signal", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 2. Elapsed Time Component
ggplot(df_vis, aes(x = Sample)) +
  geom_line(aes(y = Original), color = "#253494", size = 1, alpha = 0.5) +
  geom_line(aes(y = Time_Component), color = "#457b9d", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "2. Time Component",
       x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 3. After Time Correction
ggplot(df_vis, aes(x = Sample, y = After_Time_Correction)) +
  geom_line(color = "#1c9099", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "3. After Time Correction", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 4. Batch Component
ggplot(df_vis, aes(x = Sample)) +
  geom_line(aes(y = After_Time_Correction), color = "#1c9099", size = 1, alpha = 0.5) +
  geom_line(aes(y = Batch_Component), color = "#e9c46a", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "4. Batch Component",
       x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 5. Final Corrected Signal
ggplot(df_vis, aes(x = Sample, y = Fully_Corrected)) +
  geom_line(color = "#006d2c", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "5. Final Corrected Signal", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

```

After visualizing the sequential correction (elapsed time followed by batch), we now apply the same procedure in reverse order. This serves to confirm whether the correction is stable and order-independent for this dataset.


```{r inverse, fig.width=6, fig.height=2, echo=FALSE}

# Apply corrections in reverse order
corr_batch_first <- correction(intensities, df$batch)
intensities_batch_first <- corr_batch_first$corrected

corr_time_second <- correction(intensities_batch_first, df$elapsed_time)
intensities_inverse <- corr_time_second$corrected

# Intermediate projections
batch_projection_inv <- corr_batch_first$projection
time_projection_inv <- corr_time_second$projection

# Select same cluster and center
example_cluster_inv <- intensities[, 18]
signal_mean_inv <- mean(example_cluster_inv)

df_vis_inv <- data.frame(
  Sample = 1:length(example_cluster_inv),
  Original = example_cluster_inv - signal_mean_inv,
  Batch_Component = batch_projection_inv[, 18],
  After_Batch_Correction = example_cluster_inv - signal_mean_inv - batch_projection_inv[, 18],
  Time_Component = time_projection_inv[, 18],
  Fully_Corrected = intensities_inverse[, 18] - signal_mean_inv
)

y_limits_inv <- range(df_vis_inv)

# 1. Original Signal
ggplot(df_vis_inv, aes(x = Sample, y = Original)) +
  geom_line(color = "#1D3557", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "1. Original Signal", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 2. Batch Component
ggplot(df_vis_inv, aes(x = Sample)) +
  geom_line(aes(y = Original), color = "#1D3557", size = 1, alpha = 0.5) +
  geom_line(aes(y = Batch_Component), color = "#e9c46a", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "2. Batch Component", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 3. After Batch Correction
ggplot(df_vis_inv, aes(x = Sample, y = After_Batch_Correction)) +
  geom_line(color = "#2a9d8f", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "3. After Batch Correction", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 4. Time Component
ggplot(df_vis_inv, aes(x = Sample)) +
  geom_line(aes(y = After_Batch_Correction), color = "#2a9d8f", size = 1, alpha = 0.5) +
  geom_line(aes(y = Time_Component), color = "#457b9d", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "4. Time Component", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

# 5. Final Corrected Signal
ggplot(df_vis_inv, aes(x = Sample, y = Fully_Corrected)) +
  geom_line(color = "#264653", size = 1) +
  theme_minimal(base_size = 9) +
  labs(title = "5. Final Corrected Signal", x = "Sample", y = "Centered Intensity") +
  ylim(y_limits_inv) +
  theme(plot.title = element_text(size = 10, hjust = 0.5),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())
```

The plots below demonstrate that the final corrected signal remains consistent, regardless of the order in which external effects are removed.

## 6. Results

### 6.1 Variance Explained

Variance explained before and after correction:

```{r explained-variance}
explained_variance <- function(data, variable){
  apply(data, 2, function(x){ summary(lm(x ~ variable))$r.squared }) %>% mean()
}

elapsed_original <- explained_variance(intensities, df$elapsed_time)
elapsed_corrected <- explained_variance(intensities_final, df$elapsed_time)
batch_original <- explained_variance(intensities, df$batch)
batch_corrected <- explained_variance(intensities_final, df$batch)

variance_df <- data.frame(
  Condition = c("Original", "Corrected"),
  Elapsed_Time = paste0(round(c(elapsed_original, elapsed_corrected) * 100, 2), " %"),
  Batch = paste0(round(c(batch_original, batch_corrected) * 100, 2), " %")
)


print(variance_df)
```

The reduction in explained variance after correction confirms the effective removal of systematic variability due to elapsed time and batch effects.


### 6.2 Principal Component Analysis (PCA) Visualizations


To better understand the structure of the data and the impact of the orthogonalization steps, we perform a Principal Component Analysis (PCA) on the cluster intensity matrix. The PCA is first computed on the original, uncorrected data, and the resulting components are used as a reference space for later projections.

We begin by displaying the projection of the original data on the first two principal components, colored by elapsed time.

```{r pca-original-dataframe, echo=FALSE}
# Scale original data before PCA
intensities_scaled <- scale(intensities)

# Perform PCA
pca <- prcomp(intensities_scaled)

# Extract explained variance for axis labels
explained_var <- summary(pca)$importance[2, ] * 100
axis_labels <- paste0("PC", 1:2, " (", round(explained_var[1:2], 1), "%)")

# Build PCA dataframe with metadata for coloring
pca_df <- data.frame(
  PC1 = pca$x[, 1],
  PC2 = pca$x[, 2],
  Elapsed_Time = df$elapsed_time,
  Batch = as.factor(df$batch)
)
```


```{r pca-originals, echo=FALSE, warning=FALSE, fig.width=12, fig.height=4.5, fig.cap = "PCA of original data colored by elapsed time (left) and by batch (right)", fig.align='center'}

p1 <- plot_pca(pca_df, "Elapsed_Time", "Colored by Elapsed Time",
               scale_color_gradientn(colours = hcl.colors(100, "YlGnBu")))

p2 <- plot_pca(pca_df, "Batch", "Colored by Batch",
               scale_color_discrete())

p1 + p2
```

```{r pca-variance-distribution, echo=FALSE, warning=FALSE, fig.width=5, fig.height=3, fig.cap = "Variance explained by each principal component (original data)", fig.align='center'}

var_df <- data.frame(PC = paste0("PC", 1:6),
                     Variance = explained_var[1:6])

ggplot(var_df, aes(x = PC, y = Variance)) +
  geom_col(fill = "#A8DADC") +
  theme_minimal(base_size = 13) +
  labs(title = "PCA Components — Variance Explained",
       x = "Principal Component", y = "Explained Variance (%)") +
  theme(axis.text.x = element_text(size = 11))
```


The following plots show how the data distribution changes after correcting for elapsed time. The PCA components are the same as in the original (uncorrected) analysis, and the corrected data is projected into this fixed PCA space for comparison.

```{r pca-correction-elapsed-fixed, echo=FALSE, warning=FALSE, fig.width=12, fig.height=4.5, fig.cap = "Projection before (left) and after (right) elapsed time correction, both colored by elapsed time", fig.align='center'}

# Project time-corrected data into the original PCA space
projected_time <- scale(intensities_time_corr,
                        center = attr(intensities_scaled, "scaled:center"),
                        scale = attr(intensities_scaled, "scaled:scale")) %*% pca$rotation

plot_pca_2(
  data1 = pca_df,
  data2 = data.frame(PC1 = projected_time[,1], PC2 = projected_time[,2], Elapsed_Time = df$elapsed_time),
  color_var = "Elapsed_Time",
  title1 = "Original",
  title2 = "After Time Correction",
  color_scale = scale_color_gradientn(colours = hcl.colors(100, "YlGnBu"))
)

```

The following plots show the impact of correcting for batch effects while leaving elapsed time uncorrected. As before, both datasets are projected into the same PCA space and colored by batch number.

```{r pca-correction-batch, echo=FALSE, warning=FALSE, fig.width=12, fig.height=4.5, fig.cap = "Projection before (left) and after (right) batch correction, both colored by batch", fig.align='center'}

# Project batch-corrected data into the original PCA space
projected_batch <- scale(intensities_batch_first,
                         center = attr(intensities_scaled, "scaled:center"),
                         scale = attr(intensities_scaled, "scaled:scale")) %*% pca$rotation

plot_pca_2(
  data1 = pca_df,
  data2 = data.frame(PC1 = projected_batch[,1], PC2 = projected_batch[,2], Batch = as.factor(df$batch)),
  color_var = "Batch",
  title1 = "Original",
  title2 = "After Batch Correction",
  color_scale = scale_color_discrete()
)
```


We now compare the full correction (elapsed time + batch) against the original data. Both datasets are projected into the same PCA space. 

```{r pca-correction-full, echo=FALSE, warning=FALSE, fig.width=10, fig.height=4.5, fig.cap = "Projection before (left) and after (right) full correction (no coloring)", fig.align='center'}

# Project fully corrected data into the original PCA space
projected_full <- scale(intensities_final,
                        center = attr(intensities_scaled, "scaled:center"),
                        scale = attr(intensities_scaled, "scaled:scale")) %*% pca$rotation

# Datasets sense color
data1 <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2])
data2 <- data.frame(PC1 = projected_full[,1], PC2 = projected_full[,2])

p1 <- ggplot(data1, aes(x = PC1, y = PC2)) +
  geom_point(size = 2, color = "#888888") +
  coord_cartesian(xlim = range(c(data1$PC1, data2$PC1)),
                  ylim = range(c(data1$PC2, data2$PC2))) +
  theme_minimal(base_size = 13) +
  labs(title = "Original", x = axis_labels[1], y = axis_labels[2]) +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

p2 <- ggplot(data2, aes(x = PC1, y = PC2)) +
  geom_point(size = 2, color = "#1D3557") +
  coord_cartesian(xlim = range(c(data1$PC1, data2$PC1)),
                  ylim = range(c(data1$PC2, data2$PC2))) +
  theme_minimal(base_size = 13) +
  labs(title = "After Full Correction", x = axis_labels[1], y = axis_labels[2]) +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

p1 + p2
```
Finally, we perform a new PCA using the fully corrected dataset. The plots below show the distribution of samples in the new PCA space, colored by elapsed time and batch, respectively. A barplot of the explained variance is also included.

```{r pca-corrected-plot, echo=FALSE, warning=FALSE, fig.width=12, fig.height=4.5, fig.cap = "PCA of corrected data colored by elapsed time (left) and by batch (right)", fig.align='center'}

# PCA on corrected data
pca_corrected <- prcomp(scale(intensities_final))
explained_var_corr <- summary(pca_corrected)$importance[2, ] * 100
axis_labels <- paste0("PC", 1:2, " (", round(explained_var_corr[1:2], 1), "%)")

pca_df_corr <- data.frame(PC1 = pca_corrected$x[,1], PC2 = pca_corrected$x[,2],
                          Elapsed_Time = df$elapsed_time,
                          Batch = as.factor(df$batch))

p1 <- plot_pca(pca_df_corr, "Elapsed_Time", "Colored by Elapsed Time",
               scale_color_gradientn(colours = hcl.colors(100, "YlGnBu")))

p2 <- plot_pca(pca_df_corr, "Batch", "Colored by Batch",
               scale_color_discrete())

p1 + p2
```
```{r pca-variance-distribution-corr, echo=FALSE, warning=FALSE, fig.width=5, fig.height=3, fig.cap = "Variance explained by each principal component (corrected data)", fig.align='center'}

var_df_corr <- data.frame(PC = paste0("PC", 1:6),
                          Variance = explained_var_corr[1:6])

ggplot(var_df_corr, aes(x = PC, y = Variance)) +
  geom_col(fill = "#A8DADC") +
  theme_minimal(base_size = 13) +
  labs(title = "Corrected PCA — Variance Explained",
       x = "Principal Component", y = "Explained Variance (%)") +
  theme(axis.text.x = element_text(size = 11))

```




